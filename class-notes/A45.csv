"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"25EATXRY","journalArticle","2017","Brooks, Christopher; Thompson, Craig","Predictive modelling in teaching and learning","Handbook of learning analytics","","","","","","2017","2017-11-15 16:39:59","2017-11-15 16:39:59","","61–68","","","","","","","","","","","","","","","","","","Google Scholar","","","<p><strong>Brooks &amp; Thompson, 2017 Notes</strong></p> <ul> <li>A chapter introducing predictive analytics.</li> <li>Predictive analytics are techniques to ""make inferences about uncertain future events"" p.61</li> <li>Explanatory modelling the aim is to explain an event/ trend in the past using all available data already collected. It is ""post-hoc and reflective"" p.62 <ul> <li>Usually, the ""intent of these explanation is generally to be causal"" p.61</li> <li>Data ususally collected from a sample and aim is to generalize.</li> <li>Not necessarily implemented to result in changes in interventions etc</li> </ul> </li> <li>Predictive modelling is to create a model to predict the values/ class of new data based on observations. p.61 <ul> <li>Assumes known data can be used to train a machine to predict new data.</li> <li>It is ""in situ"" and designed to lead to changes. More action-focused and designed for real-time use p.62</li> <li>Datasets are often split into two, with one used for training and a second ""hold out"" set used to evaluate effectiveness of a model.</li> </ul> </li> <li>""the principal difference...is with the application of the model to future events, where explanatory modelling does not aim to make any claims about the future, while predictive modelling does."" p.62</li> <li>Predictive modelling best used: <ul> <li>Quantifiable characteristics of the phenomenon/ problem in focus.</li> <li>Understanding of goals and what the output looks like.</li> <li>Large dataset.</li> <li>""recurring need"" where you can accurately use past data to predict future data. I.e. data will also exist in the future.</li> </ul> </li> <li>Steps to do predictive modelling: <ul> <li>Identify outcome variable.</li> <li>Identify the suspected correlates of this variable.</li> <li>Often you'll have to do feature selection on the dataset, since it can be large and complex. <ul> <li>Look at correlation between variables and remove highly correlated variables (avoid multicollinearity). p.63</li> </ul> </li> <li>Deal with missing data- different options with different implications/ affects. p.64</li> <li>Choose algorithm. Lots of options- good overview p.64. <ul> <li>Linear regression.</li> <li>Logistic regression.</li> <li>Nearest neighbors classifiers.</li> <li>Decision tree.</li> <li>Naive Bayes classifiers.</li> <li>Bayesian networks.</li> <li>Support vector machines.</li> <li>Neural networks.</li> <li>Ensemble method.</li> </ul> </li> <li>Test the 'goodness fit'/ prediction accuracy of a model. <ul> <li>Recommend k-fold cross validation rather than having a 'hold out' set of data.</li> </ul> </li> </ul> </li> <li>Classification algorithms are used to predict categorical values (categorical, ordinal data).</li> <li>Regression algorithms are used to predict numerical values (interval, ratio etc).</li> </ul>","/Users/melanienethercott/Zotero/storage/HDU76WZT/HDU76WZT.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LJV56DL9","bookSection","2017","Carnegie Mellon University, USA; Liu, Ran; Koedinger, Kenneth R.; Carnegie Mellon University, USA","Going Beyond Better Data Prediction to Create Explanatory Models of Educational Data","Handbook of Learning Analytics","978-0-9952408-0-3","","","https://solaresearch.org/hla-17/hla17-chapter6","","2017-05","2017-11-27 15:34:41","2017-11-27 15:34:41","2017-11-27 15:34:41","69-76","","","","","","","","","","","Society for Learning Analytics Research (SoLAR)","","","","","","","CrossRef","","DOI: 10.18608/hla17.006","<p><strong>Liu &amp; Koedinger, 2017 Notes</strong></p> <ul> <li>Argue for explanatory models over predictive models in EDM for better ""interpretability and actionability of educational data mining efforts"".<br /> <ul> <li>Need to understand WHY the model has more accurate predictions.</li> <li>And WHY and HOW this affects instructional design. p.73</li> </ul> </li> <li>""Explanatory models seek to identify interpretable constructions that are causally related to outcomes...they provide an explanation of the data that can be connected to existing theory. The focus is on <em>why</em> a model fits the data well rather than only <em>that</em> it fits well."" p.69</li> <li>Authors focus on cognitive models which ""map knowledge components (i.e., concepts, skills, and facts;...) to problem steps or tasks on which student performance can be observed."" <ul> <li>This means you can infer about student knowledge based on performance on specific tasks. p.70</li> <li>KC model or Q-matrix capture these knowledge components.</li> </ul> </li> <li>Talk about Difficulty factors assessment: <ul> <li>i.e. a harder task involves a knowledge component which is not required in an easier task.</li> <li>Authors find DFA is great for refining explanatory KC models to help improve instruction. p.71</li> </ul> </li> <li>Learning factors analysis:<br /> <ul> <li>""searches across hypothesized knowledge components drawn from different existing KC models, evaluates different modesl based on their fit to data, and outputs the best-fitting KC model in the form of a symbolic model"".</li> <li>Reduced human effort and increases interpretability</li> </ul> </li> <li>Key characteristics of explanatory models pp.73-74: <ul> <li>""clean"" independent variables- i.e. neatly delineated constructs or simple functions.</li> <li>Usually ""feature representations motivated by interpretable, theoretical frameworks"" are the best for turning raw data into data to be analyzed via machine-learning.</li> <li>To support actionability, the dependent variable should map onto a ""well-defined construct"".</li> <li>Tend to have less parameters and independent variables/ features (to support interpretability and ensure the explanatory power is greater).</li> <li>Interpretability is required, basically: ""'this 'human-in-the-loop' feature leads the results of such modelling efforts to be explanatory."" p.72 <ul> <li>Using human effort first helps and then the data-driven element reduces any biases. ""Methods such as LFA leverage both the unique strengths of human involvement and of automation towards creating models that are more predictive <em>and</em> explanatory."" p.73</li> </ul> </li> </ul> </li> </ul>","/Users/melanienethercott/Zotero/storage/XV933T2F/Liu & Koedinger, 2017.pdf","","","","Columbia University, USA; Lang, Charles; Siemens, George; University of Texas at Arlington, USA; Wise, Alyssa; New York University, USA; Gasevic, Dragan; University of Edinburgh, UK","","","","","","","","","","","","","","","","","","","First","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EKBWJ2QQ","journalArticle","2003","Alfaro, Michael E.; Zoller, Stefan; Lutzoni, François","Bayes or bootstrap? A simulation study comparing the performance of Bayesian Markov chain Monte Carlo sampling and bootstrapping in assessing phylogenetic confidence","Molecular Biology and Evolution","","","","","","2003","2017-11-27 16:50:27","2017-11-27 16:50:27","","255–266","","2","20","","","Bayes or bootstrap?","","","","","","","","","","","","Google Scholar","","","<p><strong>Zheng, 2015 Notes</strong></p> <ul> <li>Evaluation metrics are used in machine learning.</li> <li>This chapter looks at supervised learning models evaluation metrics.</li> </ul> <p>Classification</p> <ul> <li>Classification metrics: predicting class labels based on data provided. Can be binary or mult-class classifications.</li> <li>Classification performance can be measured using: accuracy, confusion matrix, log-loss, AUC, and precision-recall.</li> <li><strong>Accuracy:</strong> measures ""how often the classifier makes the correct prediction"". <ul> <li>Correct predictions divided by total number of predictions.</li> <li>Makes no distinction between classes i.e. how accurate was prediction in class 1 versus class 0.</li> </ul> </li> <li><strong>Confusion matrix:</strong> allows you to look at prediction accuracy by class. Rows of the matrix correspond to actual data truths, and columns represent the prediction.</li> <li><strong>Per-class accuracy:</strong> average accuracy within each class (macro-average). If classes are imbalanced, accuracy distorts the picture and per-class accuracy takes this into account. <ul> <li>But if this imbalance is very large, the variance is large and the estimate won't be as reliable.</li> <li>Also, the average ""obscures the confidence measurement of individual classes"".</li> </ul> </li> <li><strong>Log-loss:</strong> is a measure of accuracy which also draws on probabalistic confidence. Use when the output is a numeric probability instead of binary class labels p.9 <ul> <li>Log-loss helps identify the additional noise that occurs when using predictors rather than actual data. The algorithm minimizes cross entropy to ""maximize the accuracy of the classifier"" p.10</li> </ul> </li> <li><strong>AUC</strong>- area under the curve: curve is the ROC curve which shows you ""how many correct positive classifications can be gained as you allow for more and more false positives."" p.10 <ul> <li>AUC helps to summarize the ROC curve into a number, to support comparison. A high AUC is good, and low AUC is less good.</li> </ul> </li> <li><strong>Precision-recall</strong>: a ranking metric that can be used for classification tasks. <ul> <li>Precision: of all the items predicted to be relevant, how many are actually relevant?</li> <li>Recall: of all the items that are actually relevant, how many are found by the rank/ classifier?</li> <li>Think of each as a circle in the venn diagram and the overlap as the 'best answers'.</li> <li>Can average the precision and recall scores to get something similar to accuracy per class.</li> </ul> </li> </ul> <p>Ranking</p> <ul> <li>Can encompass some binary classification before ordering by assigning a number score to all items rather than a category label.</li> </ul>","/Users/melanienethercott/Zotero/storage/678LSDZZ/678LSDZZ.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2QIN34V5","journalArticle","1994","Corbett, Albert T.; Anderson, John R.","Knowledge tracing: Modeling the acquisition of procedural knowledge","User modeling and user-adapted interaction","","","","","","1994","2017-12-07 18:29:21","2017-12-07 18:29:21","","253–278","","4","4","","","Knowledge tracing","","","","","","","","","","","","Google Scholar","","","<p><strong>Corbett &amp; Anderson, 1995 Notes</strong></p> <ul> <li>Authors are looking at an ACT Programing Tutor and implement a model that allows the tutor to track the students' knowledge state and then tailor following content for the student to practice and work towards knowledge mastery. <ul> <li>This is referred to as a knowledge tracing process.</li> </ul> </li> <li>The authors built a model to assess the students' knowledge state based on previous performance and predict performance from that.</li> <li>Their model predicts performance relatively well and the support given to students to work towards mastery helps them to reach a high level of performance.</li> <li>The authors think by changing incentives in the APT, students might even perform better.</li> </ul>","/Users/melanienethercott/Zotero/storage/NCSQ47NP/Corbett & Anderson, 1995.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""